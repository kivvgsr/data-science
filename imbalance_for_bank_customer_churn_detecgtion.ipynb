{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObgSCTe6MU3ZZjhodOr0yy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kivvgsr/data-science/blob/main/imbalance_for_bank_customer_churn_detecgtion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUrhCR4yHHHU",
        "outputId": "68812222-699b-4536-b62a-95463658d69a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
            "0          1    15634602  Hargrave          619    France  Female   42   \n",
            "1          2    15647311      Hill          608     Spain  Female   41   \n",
            "2          3    15619304      Onio          502    France  Female   42   \n",
            "3          4    15701354      Boni          699    France  Female   39   \n",
            "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
            "\n",
            "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
            "0       2       0.00              1          1               1   \n",
            "1       1   83807.86              1          0               1   \n",
            "2       8  159660.80              3          1               0   \n",
            "3       1       0.00              2          0               0   \n",
            "4       2  125510.82              1          1               1   \n",
            "\n",
            "   EstimatedSalary  Exited  \n",
            "0        101348.88       1  \n",
            "1        112542.58       0  \n",
            "2        113931.57       1  \n",
            "3         93826.63       0  \n",
            "4         79084.10       0  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# Define the Google Drive file ID\n",
        "file_id = '1nKKXywzeylOfrD3sQTXAY2nT7t5gF5bL'\n",
        "\n",
        "# Define the URL to download the file from Google Drive\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "\n",
        "# Define the output file name\n",
        "output = 'dataset.csv'\n",
        "\n",
        "# Download the file from Google Drive using requests\n",
        "response = requests.get(url)\n",
        "\n",
        "# Write the contents to the output file\n",
        "with open(output, 'wb') as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "# Load the dataset using pandas\n",
        "data = pd.read_csv(output)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(data.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "JPFKQIZVHkQf"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "df =  data"
      ],
      "metadata": {
        "id": "ZnvHXpIyHmol"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop('CustomerId',axis = 'columns',inplace=True)\n",
        "\n",
        "df.drop(['RowNumber','Surname'],axis='columns',inplace=True)"
      ],
      "metadata": {
        "id": "MBBwyxxRHpzp"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6p1NYC9OHysh",
        "outputId": "afb4b2fb-e020-4c20-ba60-0c8d1bd58ea5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CreditScore          int64\n",
              "Geography           object\n",
              "Gender              object\n",
              "Age                  int64\n",
              "Tenure               int64\n",
              "Balance            float64\n",
              "NumOfProducts        int64\n",
              "HasCrCard            int64\n",
              "IsActiveMember       int64\n",
              "EstimatedSalary    float64\n",
              "Exited               int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lets  get the unique values in the each column\n",
        "def print_unique_col(df):\n",
        "  for columns in df:\n",
        "    if df[columns].dtypes == 'object' :\n",
        "      print(f'{columns}:{df[columns].unique()}')"
      ],
      "metadata": {
        "id": "eXy3gufgH3bd"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_unique_col(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLwsw1PYH6CW",
        "outputId": "e6123a92-91a0-4ac3-efbb-dd394b0d284e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Geography:['France' 'Spain' 'Germany']\n",
            "Gender:['Female' 'Male']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Gender'].replace({'Female':1,\"Male\":0},inplace=True)\n",
        "\n",
        "df.Gender.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9YSpxMsH8kd",
        "outputId": "5ba49b6f-736b-4218-a03c-8019ddbe9f1e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lets  get the unique values in the each column\n",
        "def print_unique_col(df):\n",
        "  for columns in df:\n",
        "    if df[columns].dtypes == 'object' :\n",
        "      print(f'{columns}:{df[columns].unique()}')"
      ],
      "metadata": {
        "id": "RVbvNk_JIb3A"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_unique_col(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OU9jeOiIe_v",
        "outputId": "4f412fe1-6e93-42d7-8e16-0b233265e04c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Geography:['France' 'Spain' 'Germany']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.get_dummies(data = df,columns=['Geography'])\n",
        "df1.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YI2p6h_UIiT6",
        "outputId": "8ee5e805-973e-4913-d9c5-bcd4468daf85"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['CreditScore', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts',\n",
              "       'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Exited',\n",
              "       'Geography_France', 'Geography_Germany', 'Geography_Spain'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_scale = ['Tenure','CreditScore','Age','Balance','NumOfProducts','EstimatedSalary']\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "df1[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])"
      ],
      "metadata": {
        "id": "thy-Jv-LIo1B"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head()\n",
        "for col in(df1):\n",
        "  print(f'{col}:{df1[col].unique()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHmhwT0PItKg",
        "outputId": "68ff0b51-a45b-4822-c3bf-1c8457094585"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CreditScore:[0.538 0.516 0.304 0.698 1.    0.59  0.944 0.052 0.302 0.668 0.356 0.294\n",
            " 0.252 0.398 0.57  0.532 0.606 0.474 0.752 0.764 0.572 0.32  0.638 0.992\n",
            " 0.454 0.812 0.442 0.448 0.122 0.482 0.366 0.406 0.34  0.744 0.25  0.28\n",
            " 0.908 0.464 0.244 0.23  0.412 0.968 0.62  0.852 0.958 0.574 0.4   0.696\n",
            " 0.47  0.876 0.61  0.502 0.612 0.75  0.322 0.528 0.784 0.674 0.41  0.506\n",
            " 0.802 0.462 0.77  0.622 0.65  0.776 0.926 0.614 0.508 0.338 0.628 0.656\n",
            " 0.814 0.132 0.63  0.854 0.386 0.312 0.286 0.604 0.8   0.758 0.592 0.594\n",
            " 0.916 0.348 0.838 0.76  0.33  0.846 0.928 0.72  0.126 0.546 0.64  0.544\n",
            " 0.87  0.51  0.258 0.67  0.376 0.424 0.742 0.556 0.636 0.956 0.648 0.55\n",
            " 0.164 0.84  0.816 0.89  0.672 0.878 0.478 0.222 0.468 0.458 0.626 0.664\n",
            " 0.886 0.682 0.27  0.6   0.808 0.37  0.732 0.378 0.712 0.472 0.562 0.734\n",
            " 0.9   0.666 0.708 0.53  0.634 0.268 0.26  0.456 0.324 0.512 0.494 0.856\n",
            " 0.328 0.35  0.73  0.46  0.914 0.342 0.818 0.332 0.722 0.536 0.586 0.642\n",
            " 0.678 0.54  0.652 0.444 0.69  0.484 0.434 0.688 0.394 0.488 0.646 0.52\n",
            " 0.834 0.826 0.724 0.706 0.624 0.618 0.346 0.844 0.39  0.568 0.778 0.842\n",
            " 0.662 0.388 0.692 0.832 0.754 0.686 0.414 0.362 0.296 0.602 0.882 0.766\n",
            " 0.922 0.714 0.728 0.864 0.85  0.898 0.504 0.788 0.476 0.794 0.466 0.554\n",
            " 0.762 0.558 0.176 0.584 0.912 0.248 0.418 0.158 0.66  0.798 0.768 0.588\n",
            " 0.552 0.598 0.91  0.736 0.98  0.56  0.608 0.824 0.436 0.526 0.344 0.774\n",
            " 0.596 0.186 0.58  0.38  0.22  0.486 0.902 0.522 0.904 0.79  0.266 0.68\n",
            " 0.284 0.718 0.71  0.42  0.804 0.702 0.374 0.274 0.492 0.704 0.272 0.748\n",
            " 0.396 0.228 0.88  0.368 0.796 0.288 0.48  0.236 0.318 0.936 0.932 0.372\n",
            " 0.806 0.848 0.542 0.438 0.616 0.896 0.582 0.384 0.684 0.578 0.83  0.44\n",
            " 0.576 0.498 0.564 0.858 0.354 0.428 0.966 0.308 0.984 0.316 0.134 0.496\n",
            " 0.782 0.514 0.822 0.996 0.392 0.178 0.81  0.82  0.352 0.726 0.7   0.632\n",
            " 0.432 0.29  0.676 0.524 0.254 0.154 0.978 0.938 0.74  0.218 0.306 0.548\n",
            " 0.358 0.426 0.264 0.892 0.19  0.792 0.872 0.408 0.644 0.874 0.298 0.988\n",
            " 0.2   0.93  0.976 0.906 0.772 0.566 0.5   0.658 0.334 0.884 0.786 0.276\n",
            " 0.142 0.982 0.716 0.314 0.31  0.212 0.17  0.422 0.336 0.43  0.756 0.868\n",
            " 0.404 0.518 0.828 0.694 0.746 0.402 0.188 0.738 0.292 0.382 0.96  0.924\n",
            " 0.654 0.14  0.49  0.534 0.918 0.3   0.952 0.168 0.326 0.256 0.894 0.026\n",
            " 0.098 0.226 0.86  0.204 0.45  0.974 0.888 0.948 0.156 0.946 0.862 0.998\n",
            " 0.278 0.162 0.214 0.836 0.962 0.018 0.94  0.446 0.452 0.416 0.934 0.198\n",
            " 0.18  0.13  0.942 0.36  0.    0.192 0.15  0.78  0.262 0.866 0.016 0.99\n",
            " 0.202 0.216 0.238 0.146 0.108 0.972 0.246 0.97  0.232 0.282 0.002 0.954\n",
            " 0.986 0.03  0.364 0.128 0.206 0.242 0.102 0.92  0.964 0.24  0.194 0.144\n",
            " 0.95  0.16  0.172 0.152 0.116 0.994 0.136 0.174 0.12  0.208 0.114 0.21\n",
            " 0.224 0.072 0.11  0.066 0.09  0.234 0.166 0.184 0.148 0.196 0.182 0.034\n",
            " 0.124 0.064 0.046 0.138]\n",
            "Gender:[1 0]\n",
            "Age:[0.32432432 0.31081081 0.28378378 0.33783784 0.35135135 0.43243243\n",
            " 0.14864865 0.12162162 0.17567568 0.08108108 0.21621622 0.09459459\n",
            " 0.22972973 0.36486486 0.54054054 0.18918919 0.27027027 0.37837838\n",
            " 0.24324324 0.2027027  0.2972973  0.44594595 0.58108108 0.41891892\n",
            " 0.25675676 0.01351351 0.64864865 0.51351351 0.10810811 0.04054054\n",
            " 0.5        0.77027027 0.05405405 0.16216216 0.13513514 0.63513514\n",
            " 0.40540541 0.45945946 0.52702703 0.74324324 0.39189189 0.48648649\n",
            " 0.72972973 0.02702703 0.66216216 0.82432432 0.59459459 0.47297297\n",
            " 0.83783784 0.55405405 0.67567568 0.06756757 0.56756757 0.7027027\n",
            " 0.60810811 0.62162162 0.         0.86486486 0.68918919 0.75675676\n",
            " 0.71621622 0.78378378 0.7972973  0.94594595 0.90540541 0.89189189\n",
            " 0.81081081 0.85135135 1.         0.87837838]\n",
            "Tenure:[0.2 0.1 0.8 0.7 0.4 0.6 0.3 1.  0.5 0.9 0. ]\n",
            "Balance:[0.         0.33403148 0.63635718 ... 0.22865702 0.29922631 0.51870777]\n",
            "NumOfProducts:[0.         0.66666667 0.33333333 1.        ]\n",
            "HasCrCard:[1 0]\n",
            "IsActiveMember:[1 0]\n",
            "EstimatedSalary:[0.50673489 0.56270874 0.56965435 ... 0.21039009 0.46442905 0.19091423]\n",
            "Exited:[1 0]\n",
            "Geography_France:[1 0]\n",
            "Geography_Germany:[0 1]\n",
            "Geography_Spain:[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df1.drop('Exited',axis='columns')\n",
        "y = df1['Exited']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=5)\n"
      ],
      "metadata": {
        "id": "EjBQkUQsIxIn"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4unVozYI05e",
        "outputId": "f25d845c-712f-4431-b011-4459b0992fee"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8qHhp50I3z1",
        "outputId": "bb37926d-2b8e-45dd-c1f6-10edc8c7fd8a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rgTmoyBcb4_",
        "outputId": "2f1c302f-89ec-40fd-fc73-ca0d1a93e3e7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow_addons import losses\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import confusion_matrix , classification_report\n"
      ],
      "metadata": {
        "id": "g3OaRY19cU7l"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ANN(X_train, y_train, X_test, y_test, loss, weights):\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Dense(26, input_dim=12, activation='relu'),\n",
        "        keras.layers.Dense(15, activation='relu'),\n",
        "        keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
        "\n",
        "    if weights == -1:\n",
        "        model.fit(X_train, y_train, epochs=100)\n",
        "    else:\n",
        "        model.fit(X_train, y_train, epochs=100, class_weight = weights)\n",
        "\n",
        "    print(model.evaluate(X_test, y_test))\n",
        "\n",
        "    y_preds = model.predict(X_test)\n",
        "    y_preds = np.round(y_preds)\n",
        "\n",
        "    print(\"Classification Report: \\n\", classification_report(y_test, y_preds))\n",
        "\n",
        "    return y_preds"
      ],
      "metadata": {
        "id": "TcQuMOgnKBrK"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahRayhEGcx6Y",
        "outputId": "0586657d-2cec-4df0-c77e-1cf2dda6cf5a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "250/250 [==============================] - 3s 4ms/step - loss: 0.5154 - accuracy: 0.7710\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4641 - accuracy: 0.7985\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4467 - accuracy: 0.8077\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4342 - accuracy: 0.8144\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4242 - accuracy: 0.8160\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4170 - accuracy: 0.8184\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4103 - accuracy: 0.8238\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4010 - accuracy: 0.8278\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3916 - accuracy: 0.8353\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3790 - accuracy: 0.8382\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3695 - accuracy: 0.8432\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.3617 - accuracy: 0.8499\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.3560 - accuracy: 0.8490\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.3519 - accuracy: 0.8519\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3500 - accuracy: 0.8541\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3491 - accuracy: 0.8512\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3474 - accuracy: 0.8558\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3458 - accuracy: 0.8556\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3449 - accuracy: 0.8546\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3441 - accuracy: 0.8566\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3442 - accuracy: 0.8569\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3429 - accuracy: 0.8571\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3413 - accuracy: 0.8583\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3406 - accuracy: 0.8590\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3406 - accuracy: 0.8579\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3397 - accuracy: 0.8597\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3396 - accuracy: 0.8584\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3391 - accuracy: 0.8599\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3381 - accuracy: 0.8597\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8601\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3358 - accuracy: 0.8606\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3352 - accuracy: 0.8595\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3350 - accuracy: 0.8600\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3355 - accuracy: 0.8606\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3337 - accuracy: 0.8604\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3334 - accuracy: 0.8604\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3319 - accuracy: 0.8615\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3317 - accuracy: 0.8601\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8618\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8618\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3285 - accuracy: 0.8629\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3286 - accuracy: 0.8637\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8645\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3294 - accuracy: 0.8652\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3288 - accuracy: 0.8639\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3278 - accuracy: 0.8645\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3273 - accuracy: 0.8668\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3266 - accuracy: 0.8652\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3272 - accuracy: 0.8640\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3261 - accuracy: 0.8658\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3252 - accuracy: 0.8664\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3264 - accuracy: 0.8656\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3251 - accuracy: 0.8646\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3244 - accuracy: 0.8668\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3244 - accuracy: 0.8655\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3249 - accuracy: 0.8655\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3238 - accuracy: 0.8673\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3233 - accuracy: 0.8662\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3243 - accuracy: 0.8648\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3224 - accuracy: 0.8669\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8648\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3233 - accuracy: 0.8673\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3240 - accuracy: 0.8649\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3225 - accuracy: 0.8675\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3220 - accuracy: 0.8668\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3210 - accuracy: 0.8689\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3218 - accuracy: 0.8671\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3209 - accuracy: 0.8692\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3210 - accuracy: 0.8673\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3215 - accuracy: 0.8671\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3194 - accuracy: 0.8680\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3210 - accuracy: 0.8650\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3197 - accuracy: 0.8685\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3202 - accuracy: 0.8675\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3200 - accuracy: 0.8673\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8680\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.8661\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3181 - accuracy: 0.8700\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3188 - accuracy: 0.8669\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3189 - accuracy: 0.8676\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3183 - accuracy: 0.8670\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3185 - accuracy: 0.8691\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3183 - accuracy: 0.8700\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3174 - accuracy: 0.8685\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3172 - accuracy: 0.8684\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3190 - accuracy: 0.8666\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3166 - accuracy: 0.8683\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3171 - accuracy: 0.8679\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.8700\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3176 - accuracy: 0.8687\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3171 - accuracy: 0.8669\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3170 - accuracy: 0.8671\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.3171 - accuracy: 0.8695\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3168 - accuracy: 0.8705\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3162 - accuracy: 0.8698\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3157 - accuracy: 0.8698\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3166 - accuracy: 0.8706\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3167 - accuracy: 0.8694\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.3510 - accuracy: 0.8525\n",
            "[0.3509853184223175, 0.8525000214576721]\n",
            "63/63 [==============================] - 0s 1ms/step\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.95      0.91      1595\n",
            "           1       0.70      0.48      0.57       405\n",
            "\n",
            "    accuracy                           0.85      2000\n",
            "   macro avg       0.79      0.71      0.74      2000\n",
            "weighted avg       0.84      0.85      0.84      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_class_0 = df1[df1['Exited']==0]\n",
        "df_class_1 = df1[df1['Exited']==1]"
      ],
      "metadata": {
        "id": "oys_den5dX-W"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_class_0.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoBRJRzqdlM4",
        "outputId": "48381dee-cca8-43e4-e12d-e831d978898b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7963, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_class_1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVK2XmuudnyM",
        "outputId": "e47b4a75-42d2-4a49-c392-79ee84553a1d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2037, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# here we see the inbalance"
      ],
      "metadata": {
        "id": "aHVODi8sdsn1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**method 1 : undersampling**"
      ],
      "metadata": {
        "id": "YlqIoOSkdyEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_class_0_under = df_class_0.sample(n=len(df_class_1),replace=True,random_state=42)"
      ],
      "metadata": {
        "id": "fajXQfUzd27i"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_class_0_under.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNtPk23QeVR7",
        "outputId": "15562bd8-7968-4393-bbde-9d7e19b64f5b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2037, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_under=  pd.concat([df_class_0_under,df_class_1],axis=0)\n",
        "df_test_under.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78csq2w0fjIA",
        "outputId": "5a14efab-2224-434d-b004-f2d54e279149"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4074, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Random under - sampling: \")\n",
        "print(df_test_under.Exited.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acVTwbVHfm-u",
        "outputId": "11d4add0-e9b7-41d9-c273-f8e3a05e5c03"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random under - sampling: \n",
            "0    2037\n",
            "1    2037\n",
            "Name: Exited, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x= df_test_under.drop('Exited',axis = 'columns')\n",
        "y = df_test_under['Exited']"
      ],
      "metadata": {
        "id": "A8pV-x9rfvNQ"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=15, stratify=y)"
      ],
      "metadata": {
        "id": "8P0mAUuAg7XB"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.value_counts() # here because of the stratify in the y_train data we are having the equal no of entities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wJxE_c0g-Pm",
        "outputId": "fc812802-97db-424f-a3b3-db1a42466be3"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1630\n",
              "0    1629\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9t3ffYUhE7l",
        "outputId": "87db821c-88a0-45dd-8e46-cd8c790336bb"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "102/102 [==============================] - 3s 3ms/step - loss: 0.6816 - accuracy: 0.5707\n",
            "Epoch 2/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.6403 - accuracy: 0.6496\n",
            "Epoch 3/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6174 - accuracy: 0.6671\n",
            "Epoch 4/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.6001 - accuracy: 0.6784\n",
            "Epoch 5/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5862 - accuracy: 0.6901\n",
            "Epoch 6/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.5727 - accuracy: 0.7048\n",
            "Epoch 7/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.5654 - accuracy: 0.7125\n",
            "Epoch 8/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.7183\n",
            "Epoch 9/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.5476 - accuracy: 0.7303\n",
            "Epoch 10/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.5367 - accuracy: 0.7389\n",
            "Epoch 11/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.5268 - accuracy: 0.7407\n",
            "Epoch 12/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7505\n",
            "Epoch 13/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7554\n",
            "Epoch 14/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.4984 - accuracy: 0.7579\n",
            "Epoch 15/100\n",
            "102/102 [==============================] - 0s 5ms/step - loss: 0.4936 - accuracy: 0.7696\n",
            "Epoch 16/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4863 - accuracy: 0.7668\n",
            "Epoch 17/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4807 - accuracy: 0.7717\n",
            "Epoch 18/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4783 - accuracy: 0.7677\n",
            "Epoch 19/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4778 - accuracy: 0.7693\n",
            "Epoch 20/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.4733 - accuracy: 0.7717\n",
            "Epoch 21/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7732\n",
            "Epoch 22/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.4684 - accuracy: 0.7748\n",
            "Epoch 23/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.4667 - accuracy: 0.7775\n",
            "Epoch 24/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7757\n",
            "Epoch 25/100\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 0.4635 - accuracy: 0.7791\n",
            "Epoch 26/100\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 0.4648 - accuracy: 0.7785\n",
            "Epoch 27/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7760\n",
            "Epoch 28/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7766\n",
            "Epoch 29/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7766\n",
            "Epoch 30/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7782\n",
            "Epoch 31/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7815\n",
            "Epoch 32/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7824\n",
            "Epoch 33/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7815\n",
            "Epoch 34/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7818\n",
            "Epoch 35/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7831\n",
            "Epoch 36/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7782\n",
            "Epoch 37/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7809\n",
            "Epoch 38/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7828\n",
            "Epoch 39/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7800\n",
            "Epoch 40/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7877\n",
            "Epoch 41/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.7794\n",
            "Epoch 42/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7812\n",
            "Epoch 43/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.7815\n",
            "Epoch 44/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7849\n",
            "Epoch 45/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7840\n",
            "Epoch 46/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7855\n",
            "Epoch 47/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7846\n",
            "Epoch 48/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7837\n",
            "Epoch 49/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7824\n",
            "Epoch 50/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7886\n",
            "Epoch 51/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7831\n",
            "Epoch 52/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7874\n",
            "Epoch 53/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7886\n",
            "Epoch 54/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7867\n",
            "Epoch 55/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7849\n",
            "Epoch 56/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.7861\n",
            "Epoch 57/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7913\n",
            "Epoch 58/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7929\n",
            "Epoch 59/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7892\n",
            "Epoch 60/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7889\n",
            "Epoch 61/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7877\n",
            "Epoch 62/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7923\n",
            "Epoch 63/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7913\n",
            "Epoch 64/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7880\n",
            "Epoch 65/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7904\n",
            "Epoch 66/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7886\n",
            "Epoch 67/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7886\n",
            "Epoch 68/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7920\n",
            "Epoch 69/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7935\n",
            "Epoch 70/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7938\n",
            "Epoch 71/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7944\n",
            "Epoch 72/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7898\n",
            "Epoch 73/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7898\n",
            "Epoch 74/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7898\n",
            "Epoch 75/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7913\n",
            "Epoch 76/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7923\n",
            "Epoch 77/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7895\n",
            "Epoch 78/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7917\n",
            "Epoch 79/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7935\n",
            "Epoch 80/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7877\n",
            "Epoch 81/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7907\n",
            "Epoch 82/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7956\n",
            "Epoch 83/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7929\n",
            "Epoch 84/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7923\n",
            "Epoch 85/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7929\n",
            "Epoch 86/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7929\n",
            "Epoch 87/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7950\n",
            "Epoch 88/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7972\n",
            "Epoch 89/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7941\n",
            "Epoch 90/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7959\n",
            "Epoch 91/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7929\n",
            "Epoch 92/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7920\n",
            "Epoch 93/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7935\n",
            "Epoch 94/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7941\n",
            "Epoch 95/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7969\n",
            "Epoch 96/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7917\n",
            "Epoch 97/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7947\n",
            "Epoch 98/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7963\n",
            "Epoch 99/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7929\n",
            "Epoch 100/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7959\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.7632\n",
            "[0.4870310425758362, 0.7631902098655701]\n",
            "26/26 [==============================] - 0s 2ms/step\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.77      0.77       408\n",
            "           1       0.77      0.75      0.76       407\n",
            "\n",
            "    accuracy                           0.76       815\n",
            "   macro avg       0.76      0.76      0.76       815\n",
            "weighted avg       0.76      0.76      0.76       815\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#hence here our f1 score has been improved"
      ],
      "metadata": {
        "id": "17VkmACVhXVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imbalanced-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeYJ_Lo6hbjf",
        "outputId": "55073f5e-52c3-45db-94d9-6ca5096c4bcc"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**method2 : overcasting**"
      ],
      "metadata": {
        "id": "ZCzstdYQhdoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_class_0.shape,df_class_1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnxttZg8hjNN",
        "outputId": "64508313-fa8f-4279-f606-881fae1dd163"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7963, 13), (2037, 13))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_class_1_over = df_class_1.sample(n=len(df_class_0),replace = True , random_state=42)"
      ],
      "metadata": {
        "id": "7DnkGmbEiEgt"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_class_1_over.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oO1EnCXHiRtt",
        "outputId": "b0afa729-c2a8-43dd-df05-ddb5c6740ed0"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7963, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_over = pd.concat([df_class_0,df_class_1_over],axis=0)"
      ],
      "metadata": {
        "id": "c2cZ7hwSiUMP"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_class_1_over.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aL78LVVjidMg",
        "outputId": "8ee813c9-5c4d-4eff-aa55-b408f2e270a3"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7963, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Random over - sampling: \")\n",
        "print(df_test_over.Exited.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAitbIOhiggL",
        "outputId": "d92f8ebe-845e-47b7-d436-b87f581cd503"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random over - sampling: \n",
            "0    7963\n",
            "1    7963\n",
            "Name: Exited, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=df_test_over.drop('Exited',axis='columns')\n",
        "y=df_test_over['Exited']"
      ],
      "metadata": {
        "id": "DcfPF3tpil6X"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=15, stratify=y)"
      ],
      "metadata": {
        "id": "Dv7ba2ibi2e0"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.value_counts() # here because of the stratify in the y_train data we are having the equal no of entities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiYTVFwVi6ay",
        "outputId": "9ce68dfe-af5e-471f-c7fd-8d917a2f7e23"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    6370\n",
              "1    6370\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj8AJ2Gvi-XW",
        "outputId": "3e0af206-40b3-413f-f5d6-dba54663f30d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "399/399 [==============================] - 4s 6ms/step - loss: 0.6304 - accuracy: 0.6481\n",
            "Epoch 2/100\n",
            "399/399 [==============================] - 1s 4ms/step - loss: 0.5776 - accuracy: 0.7028\n",
            "Epoch 3/100\n",
            "399/399 [==============================] - 3s 8ms/step - loss: 0.5414 - accuracy: 0.7324\n",
            "Epoch 4/100\n",
            "399/399 [==============================] - 2s 6ms/step - loss: 0.5088 - accuracy: 0.7503\n",
            "Epoch 5/100\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.4895 - accuracy: 0.7596\n",
            "Epoch 6/100\n",
            "399/399 [==============================] - 2s 5ms/step - loss: 0.4790 - accuracy: 0.7651\n",
            "Epoch 7/100\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.4762 - accuracy: 0.7630\n",
            "Epoch 8/100\n",
            "399/399 [==============================] - 2s 5ms/step - loss: 0.4710 - accuracy: 0.7662\n",
            "Epoch 9/100\n",
            "399/399 [==============================] - 1s 4ms/step - loss: 0.4689 - accuracy: 0.7688\n",
            "Epoch 10/100\n",
            "399/399 [==============================] - 2s 5ms/step - loss: 0.4652 - accuracy: 0.7686\n",
            "Epoch 11/100\n",
            "399/399 [==============================] - 2s 6ms/step - loss: 0.4634 - accuracy: 0.7705\n",
            "Epoch 12/100\n",
            "399/399 [==============================] - 1s 4ms/step - loss: 0.4614 - accuracy: 0.7719\n",
            "Epoch 13/100\n",
            "399/399 [==============================] - 1s 4ms/step - loss: 0.4595 - accuracy: 0.7716\n",
            "Epoch 14/100\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.4577 - accuracy: 0.7745\n",
            "Epoch 15/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4561 - accuracy: 0.7751\n",
            "Epoch 16/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4567 - accuracy: 0.7746\n",
            "Epoch 17/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4540 - accuracy: 0.7760\n",
            "Epoch 18/100\n",
            "399/399 [==============================] - 3s 6ms/step - loss: 0.4529 - accuracy: 0.7772\n",
            "Epoch 19/100\n",
            "399/399 [==============================] - 2s 5ms/step - loss: 0.4512 - accuracy: 0.7765\n",
            "Epoch 20/100\n",
            "399/399 [==============================] - 2s 5ms/step - loss: 0.4491 - accuracy: 0.7801\n",
            "Epoch 21/100\n",
            "399/399 [==============================] - 2s 5ms/step - loss: 0.4492 - accuracy: 0.7794\n",
            "Epoch 22/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4478 - accuracy: 0.7813\n",
            "Epoch 23/100\n",
            "399/399 [==============================] - 3s 7ms/step - loss: 0.4479 - accuracy: 0.7794\n",
            "Epoch 24/100\n",
            "399/399 [==============================] - 3s 7ms/step - loss: 0.4466 - accuracy: 0.7785\n",
            "Epoch 25/100\n",
            "399/399 [==============================] - 2s 5ms/step - loss: 0.4460 - accuracy: 0.7803\n",
            "Epoch 26/100\n",
            "399/399 [==============================] - 2s 5ms/step - loss: 0.4455 - accuracy: 0.7826\n",
            "Epoch 27/100\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.4440 - accuracy: 0.7805\n",
            "Epoch 28/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4438 - accuracy: 0.7830\n",
            "Epoch 29/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4427 - accuracy: 0.7857\n",
            "Epoch 30/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4420 - accuracy: 0.7849\n",
            "Epoch 31/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4415 - accuracy: 0.7870\n",
            "Epoch 32/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4397 - accuracy: 0.7866\n",
            "Epoch 33/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4391 - accuracy: 0.7896\n",
            "Epoch 34/100\n",
            "399/399 [==============================] - 1s 4ms/step - loss: 0.4389 - accuracy: 0.7869\n",
            "Epoch 35/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4381 - accuracy: 0.7875\n",
            "Epoch 36/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4371 - accuracy: 0.7845\n",
            "Epoch 37/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4367 - accuracy: 0.7896\n",
            "Epoch 38/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4368 - accuracy: 0.7870\n",
            "Epoch 39/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4372 - accuracy: 0.7867\n",
            "Epoch 40/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4348 - accuracy: 0.7878\n",
            "Epoch 41/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4345 - accuracy: 0.7893\n",
            "Epoch 42/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4341 - accuracy: 0.7911\n",
            "Epoch 43/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4339 - accuracy: 0.7894\n",
            "Epoch 44/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4326 - accuracy: 0.7891\n",
            "Epoch 45/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4325 - accuracy: 0.7906\n",
            "Epoch 46/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4327 - accuracy: 0.7914\n",
            "Epoch 47/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4317 - accuracy: 0.7911\n",
            "Epoch 48/100\n",
            "399/399 [==============================] - 1s 4ms/step - loss: 0.4325 - accuracy: 0.7911\n",
            "Epoch 49/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4307 - accuracy: 0.7939\n",
            "Epoch 50/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4314 - accuracy: 0.7908\n",
            "Epoch 51/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4300 - accuracy: 0.7908\n",
            "Epoch 52/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4307 - accuracy: 0.7925\n",
            "Epoch 53/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4291 - accuracy: 0.7938\n",
            "Epoch 54/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4295 - accuracy: 0.7932\n",
            "Epoch 55/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4288 - accuracy: 0.7908\n",
            "Epoch 56/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4277 - accuracy: 0.7935\n",
            "Epoch 57/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4267 - accuracy: 0.7927\n",
            "Epoch 58/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4269 - accuracy: 0.7915\n",
            "Epoch 59/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4259 - accuracy: 0.7952\n",
            "Epoch 60/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4259 - accuracy: 0.7928\n",
            "Epoch 61/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4262 - accuracy: 0.7938\n",
            "Epoch 62/100\n",
            "399/399 [==============================] - 1s 4ms/step - loss: 0.4240 - accuracy: 0.7957\n",
            "Epoch 63/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4248 - accuracy: 0.7928\n",
            "Epoch 64/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4241 - accuracy: 0.7973\n",
            "Epoch 65/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4231 - accuracy: 0.7958\n",
            "Epoch 66/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4234 - accuracy: 0.7952\n",
            "Epoch 67/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4225 - accuracy: 0.7957\n",
            "Epoch 68/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4226 - accuracy: 0.7976\n",
            "Epoch 69/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4222 - accuracy: 0.7980\n",
            "Epoch 70/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4222 - accuracy: 0.7957\n",
            "Epoch 71/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4211 - accuracy: 0.7977\n",
            "Epoch 72/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4198 - accuracy: 0.7980\n",
            "Epoch 73/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4214 - accuracy: 0.7984\n",
            "Epoch 74/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4194 - accuracy: 0.7987\n",
            "Epoch 75/100\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.4201 - accuracy: 0.7978\n",
            "Epoch 76/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4186 - accuracy: 0.7987\n",
            "Epoch 77/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4184 - accuracy: 0.7976\n",
            "Epoch 78/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4189 - accuracy: 0.7990\n",
            "Epoch 79/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4176 - accuracy: 0.7964\n",
            "Epoch 80/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4176 - accuracy: 0.8009\n",
            "Epoch 81/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4169 - accuracy: 0.7992\n",
            "Epoch 82/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4173 - accuracy: 0.7974\n",
            "Epoch 83/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4172 - accuracy: 0.8004\n",
            "Epoch 84/100\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.4164 - accuracy: 0.8016\n",
            "Epoch 85/100\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.4169 - accuracy: 0.7998\n",
            "Epoch 86/100\n",
            "399/399 [==============================] - 3s 7ms/step - loss: 0.4158 - accuracy: 0.8008\n",
            "Epoch 87/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4157 - accuracy: 0.7989\n",
            "Epoch 88/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4139 - accuracy: 0.8008\n",
            "Epoch 89/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4145 - accuracy: 0.8000\n",
            "Epoch 90/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4152 - accuracy: 0.8001\n",
            "Epoch 91/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4140 - accuracy: 0.8035\n",
            "Epoch 92/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4149 - accuracy: 0.8007\n",
            "Epoch 93/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4130 - accuracy: 0.8024\n",
            "Epoch 94/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4127 - accuracy: 0.8030\n",
            "Epoch 95/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4139 - accuracy: 0.8009\n",
            "Epoch 96/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4128 - accuracy: 0.8050\n",
            "Epoch 97/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4125 - accuracy: 0.8035\n",
            "Epoch 98/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4115 - accuracy: 0.8024\n",
            "Epoch 99/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4125 - accuracy: 0.8070\n",
            "Epoch 100/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4119 - accuracy: 0.8043\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7972\n",
            "[0.42619606852531433, 0.7972379326820374]\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.75      0.79      1593\n",
            "           1       0.77      0.85      0.81      1593\n",
            "\n",
            "    accuracy                           0.80      3186\n",
            "   macro avg       0.80      0.80      0.80      3186\n",
            "weighted avg       0.80      0.80      0.80      3186\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**method3 - SMOTE**"
      ],
      "metadata": {
        "id": "A2jKhjKRnNhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = df1.drop('Exited',axis='columns')\n",
        "y = df1['Exited']"
      ],
      "metadata": {
        "id": "IBkLFDy0nTfO"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lvh46ggnflh",
        "outputId": "02a75c17-a262-4fb3-a318-f1bc449d7937"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    7963\n",
              "1    2037\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE(sampling_strategy='minority')\n",
        "x_sm,y_sm = smote.fit_resample(x,y)"
      ],
      "metadata": {
        "id": "ReJyUEGInivS"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_sm.value_counts(),y_sm.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iom5yUKinzGN",
        "outputId": "968a1cf5-c7b9-4a17-d801-0324920a59f2"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(CreditScore  Gender  Age       Tenure  Balance   NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  Geography_France  Geography_Germany  Geography_Spain\n",
              " 0.000        0       0.283784  0.0     0.437362  0.333333       0          0               0.618012         0                 1                  0                  1\n",
              " 0.680        1       0.108108  0.2     0.000000  0.333333       1          1               0.466266         0                 0                  1                  1\n",
              "              0       0.189189  0.0     0.425207  0.333333       1          1               0.689590         0                 1                  0                  1\n",
              "                                0.2     0.303262  0.000000       0          1               0.759128         0                 0                  1                  1\n",
              "                      0.202703  0.5     0.000000  0.333333       1          0               0.690096         1                 0                  0                  1\n",
              "                                                                                                                                                                    ..\n",
              " 0.516        0       0.648649  0.8     0.493967  0.000000       1          1               0.328764         0                 0                  1                  1\n",
              "              1       0.135135  0.4     0.000000  0.333333       1          0               0.054445         0                 0                  1                  1\n",
              "                                0.9     0.000000  0.333333       1          1               0.625312         1                 0                  0                  1\n",
              "                      0.162162  0.2     0.362926  0.333333       1          0               0.664871         0                 1                  0                  1\n",
              " 1.000        1       0.851351  0.1     0.000000  0.333333       1          1               0.297812         1                 0                  0                  1\n",
              " Length: 15926, dtype: int64,\n",
              " 1    7963\n",
              " 0    7963\n",
              " Name: Exited, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(x_sm,y_sm,test_size=0.2,random_state=15,stratify=y_sm)"
      ],
      "metadata": {
        "id": "r7vluVXtn-PS"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lm-3TP8WoNd2",
        "outputId": "2b131257-e212-4c7d-c2ce-2e9fba9cf817"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12740,)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ug0_bdOcodp_",
        "outputId": "cc229d3e-3f8a-4336-adc4-274e8ca8cc38"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1593\n",
              "1    1593\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pt0MjZYojwP",
        "outputId": "ec6249c9-ae8b-4669-e10a-521f24ad35c1"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "399/399 [==============================] - 4s 5ms/step - loss: 0.6365 - accuracy: 0.6385\n",
            "Epoch 2/100\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.5860 - accuracy: 0.6859\n",
            "Epoch 3/100\n",
            "399/399 [==============================] - 1s 4ms/step - loss: 0.5577 - accuracy: 0.7183\n",
            "Epoch 4/100\n",
            "399/399 [==============================] - 2s 5ms/step - loss: 0.5371 - accuracy: 0.7334\n",
            "Epoch 5/100\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.5111 - accuracy: 0.7502\n",
            "Epoch 6/100\n",
            "399/399 [==============================] - 2s 6ms/step - loss: 0.4870 - accuracy: 0.7626\n",
            "Epoch 7/100\n",
            "399/399 [==============================] - 3s 8ms/step - loss: 0.4714 - accuracy: 0.7699\n",
            "Epoch 8/100\n",
            "399/399 [==============================] - 1s 4ms/step - loss: 0.4623 - accuracy: 0.7771\n",
            "Epoch 9/100\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.4549 - accuracy: 0.7816\n",
            "Epoch 10/100\n",
            "399/399 [==============================] - 2s 5ms/step - loss: 0.4495 - accuracy: 0.7845\n",
            "Epoch 11/100\n",
            "399/399 [==============================] - 1s 4ms/step - loss: 0.4483 - accuracy: 0.7836\n",
            "Epoch 12/100\n",
            "399/399 [==============================] - 1s 4ms/step - loss: 0.4439 - accuracy: 0.7874\n",
            "Epoch 13/100\n",
            "399/399 [==============================] - 3s 8ms/step - loss: 0.4423 - accuracy: 0.7900\n",
            "Epoch 14/100\n",
            "399/399 [==============================] - 4s 9ms/step - loss: 0.4405 - accuracy: 0.7909\n",
            "Epoch 15/100\n",
            "399/399 [==============================] - 2s 5ms/step - loss: 0.4378 - accuracy: 0.7916\n",
            "Epoch 16/100\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.4362 - accuracy: 0.7960\n",
            "Epoch 17/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4380 - accuracy: 0.7934\n",
            "Epoch 18/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4359 - accuracy: 0.7950\n",
            "Epoch 19/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4345 - accuracy: 0.7936\n",
            "Epoch 20/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4336 - accuracy: 0.7951\n",
            "Epoch 21/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4324 - accuracy: 0.7967\n",
            "Epoch 22/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4331 - accuracy: 0.7941\n",
            "Epoch 23/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4315 - accuracy: 0.7958\n",
            "Epoch 24/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4312 - accuracy: 0.7964\n",
            "Epoch 25/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4312 - accuracy: 0.7980\n",
            "Epoch 26/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4293 - accuracy: 0.7981\n",
            "Epoch 27/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4289 - accuracy: 0.7987\n",
            "Epoch 28/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4286 - accuracy: 0.7988\n",
            "Epoch 29/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4275 - accuracy: 0.8000\n",
            "Epoch 30/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4270 - accuracy: 0.7983\n",
            "Epoch 31/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4261 - accuracy: 0.7992\n",
            "Epoch 32/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4256 - accuracy: 0.8022\n",
            "Epoch 33/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4252 - accuracy: 0.8017\n",
            "Epoch 34/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4250 - accuracy: 0.7985\n",
            "Epoch 35/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4247 - accuracy: 0.8002\n",
            "Epoch 36/100\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.4226 - accuracy: 0.8037\n",
            "Epoch 37/100\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.4234 - accuracy: 0.8019\n",
            "Epoch 38/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4222 - accuracy: 0.8034\n",
            "Epoch 39/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4232 - accuracy: 0.8007\n",
            "Epoch 40/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4231 - accuracy: 0.8014\n",
            "Epoch 41/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4226 - accuracy: 0.8005\n",
            "Epoch 42/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4218 - accuracy: 0.7998\n",
            "Epoch 43/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4220 - accuracy: 0.8014\n",
            "Epoch 44/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4200 - accuracy: 0.8042\n",
            "Epoch 45/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4211 - accuracy: 0.8051\n",
            "Epoch 46/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4192 - accuracy: 0.8048\n",
            "Epoch 47/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4189 - accuracy: 0.8042\n",
            "Epoch 48/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4194 - accuracy: 0.8035\n",
            "Epoch 49/100\n",
            "399/399 [==============================] - 1s 4ms/step - loss: 0.4178 - accuracy: 0.8060\n",
            "Epoch 50/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4179 - accuracy: 0.8062\n",
            "Epoch 51/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4181 - accuracy: 0.8060\n",
            "Epoch 52/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4169 - accuracy: 0.8058\n",
            "Epoch 53/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4163 - accuracy: 0.8074\n",
            "Epoch 54/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4152 - accuracy: 0.8062\n",
            "Epoch 55/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4141 - accuracy: 0.8075\n",
            "Epoch 56/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4151 - accuracy: 0.8054\n",
            "Epoch 57/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4153 - accuracy: 0.8073\n",
            "Epoch 58/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4144 - accuracy: 0.8096\n",
            "Epoch 59/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4147 - accuracy: 0.8053\n",
            "Epoch 60/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4134 - accuracy: 0.8069\n",
            "Epoch 61/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4136 - accuracy: 0.8081\n",
            "Epoch 62/100\n",
            "399/399 [==============================] - 1s 4ms/step - loss: 0.4123 - accuracy: 0.8081\n",
            "Epoch 63/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4115 - accuracy: 0.8062\n",
            "Epoch 64/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4107 - accuracy: 0.8088\n",
            "Epoch 65/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4121 - accuracy: 0.8052\n",
            "Epoch 66/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4114 - accuracy: 0.8057\n",
            "Epoch 67/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4106 - accuracy: 0.8093\n",
            "Epoch 68/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4102 - accuracy: 0.8094\n",
            "Epoch 69/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4086 - accuracy: 0.8100\n",
            "Epoch 70/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4101 - accuracy: 0.8097\n",
            "Epoch 71/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4088 - accuracy: 0.8122\n",
            "Epoch 72/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4095 - accuracy: 0.8104\n",
            "Epoch 73/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4081 - accuracy: 0.8115\n",
            "Epoch 74/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4078 - accuracy: 0.8083\n",
            "Epoch 75/100\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.4073 - accuracy: 0.8097\n",
            "Epoch 76/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4074 - accuracy: 0.8101\n",
            "Epoch 77/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4066 - accuracy: 0.8122\n",
            "Epoch 78/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4050 - accuracy: 0.8120\n",
            "Epoch 79/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4062 - accuracy: 0.8132\n",
            "Epoch 80/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4061 - accuracy: 0.8112\n",
            "Epoch 81/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4063 - accuracy: 0.8113\n",
            "Epoch 82/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4046 - accuracy: 0.8139\n",
            "Epoch 83/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4049 - accuracy: 0.8112\n",
            "Epoch 84/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4057 - accuracy: 0.8127\n",
            "Epoch 85/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4042 - accuracy: 0.8138\n",
            "Epoch 86/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4039 - accuracy: 0.8127\n",
            "Epoch 87/100\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.4024 - accuracy: 0.8141\n",
            "Epoch 88/100\n",
            "399/399 [==============================] - 2s 4ms/step - loss: 0.4038 - accuracy: 0.8113\n",
            "Epoch 89/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4013 - accuracy: 0.8173\n",
            "Epoch 90/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4026 - accuracy: 0.8141\n",
            "Epoch 91/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4019 - accuracy: 0.8130\n",
            "Epoch 92/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4016 - accuracy: 0.8141\n",
            "Epoch 93/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4021 - accuracy: 0.8130\n",
            "Epoch 94/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4007 - accuracy: 0.8170\n",
            "Epoch 95/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.4025 - accuracy: 0.8137\n",
            "Epoch 96/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.4000 - accuracy: 0.8179\n",
            "Epoch 97/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3991 - accuracy: 0.8176\n",
            "Epoch 98/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3991 - accuracy: 0.8151\n",
            "Epoch 99/100\n",
            "399/399 [==============================] - 1s 2ms/step - loss: 0.3988 - accuracy: 0.8188\n",
            "Epoch 100/100\n",
            "399/399 [==============================] - 1s 3ms/step - loss: 0.3988 - accuracy: 0.8155\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8164\n",
            "[0.40863049030303955, 0.8163841962814331]\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.81      0.82      1593\n",
            "           1       0.81      0.82      0.82      1593\n",
            "\n",
            "    accuracy                           0.82      3186\n",
            "   macro avg       0.82      0.82      0.82      3186\n",
            "weighted avg       0.82      0.82      0.82      3186\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**methos4 : use of ensamble with understanding**"
      ],
      "metadata": {
        "id": "DovA4sJpqb5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.Exited.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ddCzx52qNs2",
        "outputId": "790e6983-26a1-4a7c-9b84-77220248e58e"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    7963\n",
              "1    2037\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = df1.drop('Exited',axis='columns')\n",
        "y = df1['Exited']"
      ],
      "metadata": {
        "id": "o9OniweYqpWV"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=12,stratify=y)"
      ],
      "metadata": {
        "id": "5JAxdZZrqu4F"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBhHE1x_rHgs",
        "outputId": "e55d21bc-7269-460a-d751-f369598291a5"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    6370\n",
              "1    1630\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6370/1630 we get 3.9 it is in 1:4 ratio"
      ],
      "metadata": {
        "id": "nMA5eHrVtzLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = X_train.copy()\n",
        "df2['Exites'] = y_train"
      ],
      "metadata": {
        "id": "qphiYq2wrTuK"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2_class_0 = df2[df2.Exites == 0]\n",
        "df2_class_1 = df2[df2.Exites == 1]"
      ],
      "metadata": {
        "id": "rO9-uhWerc3M"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2_class_0.shape,df2_class_1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVFehndIrr68",
        "outputId": "fb199442-7df1-4d78-f2e9-9f7ea22e47fc"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6370, 13), (1630, 13))"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_majority(start,end):\n",
        "  df_train= pd.concat([df2_class_0[start:end],df2_class_1],axis=0)\n",
        "  x_train = df_train.drop('Exites',axis='columns')\n",
        "  y_train = df_train.Exites\n",
        "  return x_train,y_train"
      ],
      "metadata": {
        "id": "F2Vt4vo9rz-v"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,y_train = get_majority(0,1630)\n",
        "y_preds1 = ANN(x_train,y_train,X_test,y_test,'binary_crossentropy',-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35uS_TChsUIx",
        "outputId": "3b2bcf5d-5358-439d-a907-57b9347577f1"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "102/102 [==============================] - 3s 5ms/step - loss: 0.6792 - accuracy: 0.5727\n",
            "Epoch 2/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6432 - accuracy: 0.6457\n",
            "Epoch 3/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6214 - accuracy: 0.6727\n",
            "Epoch 4/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.6091 - accuracy: 0.6788\n",
            "Epoch 5/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.5973 - accuracy: 0.6856\n",
            "Epoch 6/100\n",
            "102/102 [==============================] - 0s 5ms/step - loss: 0.5868 - accuracy: 0.6966\n",
            "Epoch 7/100\n",
            "102/102 [==============================] - 0s 5ms/step - loss: 0.5799 - accuracy: 0.7000\n",
            "Epoch 8/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.5700 - accuracy: 0.7086\n",
            "Epoch 9/100\n",
            "102/102 [==============================] - 0s 5ms/step - loss: 0.5645 - accuracy: 0.7178\n",
            "Epoch 10/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.5563 - accuracy: 0.7242\n",
            "Epoch 11/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.5491 - accuracy: 0.7304\n",
            "Epoch 12/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.5426 - accuracy: 0.7344\n",
            "Epoch 13/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.7310\n",
            "Epoch 14/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.5281 - accuracy: 0.7420\n",
            "Epoch 15/100\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 0.5194 - accuracy: 0.7466\n",
            "Epoch 16/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.5144 - accuracy: 0.7472\n",
            "Epoch 17/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7555\n",
            "Epoch 18/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.5004 - accuracy: 0.7537\n",
            "Epoch 19/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.7626\n",
            "Epoch 20/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4900 - accuracy: 0.7641\n",
            "Epoch 21/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4874 - accuracy: 0.7607\n",
            "Epoch 22/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4826 - accuracy: 0.7681\n",
            "Epoch 23/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.7687\n",
            "Epoch 24/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.7663\n",
            "Epoch 25/100\n",
            "102/102 [==============================] - 0s 5ms/step - loss: 0.4736 - accuracy: 0.7733\n",
            "Epoch 26/100\n",
            "102/102 [==============================] - 0s 5ms/step - loss: 0.4718 - accuracy: 0.7736\n",
            "Epoch 27/100\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 0.4675 - accuracy: 0.7782\n",
            "Epoch 28/100\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 0.4669 - accuracy: 0.7804\n",
            "Epoch 29/100\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 0.4651 - accuracy: 0.7776\n",
            "Epoch 30/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7770\n",
            "Epoch 31/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7770\n",
            "Epoch 32/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7785\n",
            "Epoch 33/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7773\n",
            "Epoch 34/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7776\n",
            "Epoch 35/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7791\n",
            "Epoch 36/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7798\n",
            "Epoch 37/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.4561 - accuracy: 0.7752\n",
            "Epoch 38/100\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 0.4560 - accuracy: 0.7816\n",
            "Epoch 39/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.4548 - accuracy: 0.7788\n",
            "Epoch 40/100\n",
            "102/102 [==============================] - 0s 5ms/step - loss: 0.4542 - accuracy: 0.7801\n",
            "Epoch 41/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7782\n",
            "Epoch 42/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.7853\n",
            "Epoch 43/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4525 - accuracy: 0.7844\n",
            "Epoch 44/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.7785\n",
            "Epoch 45/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.7788\n",
            "Epoch 46/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7837\n",
            "Epoch 47/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.7834\n",
            "Epoch 48/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7807\n",
            "Epoch 49/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.7850\n",
            "Epoch 50/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7840\n",
            "Epoch 51/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7859\n",
            "Epoch 52/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7837\n",
            "Epoch 53/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7816\n",
            "Epoch 54/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7896\n",
            "Epoch 55/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.4476 - accuracy: 0.7816\n",
            "Epoch 56/100\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 0.4448 - accuracy: 0.7902\n",
            "Epoch 57/100\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 0.4482 - accuracy: 0.7883\n",
            "Epoch 58/100\n",
            "102/102 [==============================] - 1s 8ms/step - loss: 0.4464 - accuracy: 0.7887\n",
            "Epoch 59/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7844\n",
            "Epoch 60/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7865\n",
            "Epoch 61/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7840\n",
            "Epoch 62/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7865\n",
            "Epoch 63/100\n",
            "102/102 [==============================] - 0s 5ms/step - loss: 0.4439 - accuracy: 0.7865\n",
            "Epoch 64/100\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 0.4424 - accuracy: 0.7856\n",
            "Epoch 65/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.4449 - accuracy: 0.7890\n",
            "Epoch 66/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7905\n",
            "Epoch 67/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7880\n",
            "Epoch 68/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.7914\n",
            "Epoch 69/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7877\n",
            "Epoch 70/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7902\n",
            "Epoch 71/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7887\n",
            "Epoch 72/100\n",
            "102/102 [==============================] - 0s 5ms/step - loss: 0.4419 - accuracy: 0.7908\n",
            "Epoch 73/100\n",
            "102/102 [==============================] - 0s 5ms/step - loss: 0.4421 - accuracy: 0.7899\n",
            "Epoch 74/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7899\n",
            "Epoch 75/100\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 0.4407 - accuracy: 0.7917\n",
            "Epoch 76/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7948\n",
            "Epoch 77/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7948\n",
            "Epoch 78/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7933\n",
            "Epoch 79/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7939\n",
            "Epoch 80/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.7957\n",
            "Epoch 81/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.4363 - accuracy: 0.7926\n",
            "Epoch 82/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.4387 - accuracy: 0.7933\n",
            "Epoch 83/100\n",
            "102/102 [==============================] - 0s 5ms/step - loss: 0.4384 - accuracy: 0.7933\n",
            "Epoch 84/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7929\n",
            "Epoch 85/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.4361 - accuracy: 0.7939\n",
            "Epoch 86/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.4355 - accuracy: 0.7929\n",
            "Epoch 87/100\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 0.4358 - accuracy: 0.7942\n",
            "Epoch 88/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7972\n",
            "Epoch 89/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.4352 - accuracy: 0.7920\n",
            "Epoch 90/100\n",
            "102/102 [==============================] - 0s 5ms/step - loss: 0.4342 - accuracy: 0.7979\n",
            "Epoch 91/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.4323 - accuracy: 0.7991\n",
            "Epoch 92/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7972\n",
            "Epoch 93/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.4333 - accuracy: 0.7960\n",
            "Epoch 94/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.4334 - accuracy: 0.7945\n",
            "Epoch 95/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7945\n",
            "Epoch 96/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7957\n",
            "Epoch 97/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7957\n",
            "Epoch 98/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7982\n",
            "Epoch 99/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7982\n",
            "Epoch 100/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7975\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7870\n",
            "[0.4339732825756073, 0.7870000004768372]\n",
            "63/63 [==============================] - 0s 4ms/step\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.81      0.86      1593\n",
            "           1       0.48      0.70      0.57       407\n",
            "\n",
            "    accuracy                           0.79      2000\n",
            "   macro avg       0.70      0.75      0.71      2000\n",
            "weighted avg       0.83      0.79      0.80      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,y_train = get_majority(1630,3260)\n",
        "y_preds2 = ANN(x_train,y_train,X_test,y_test,'binary_crossentropy',-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOLLU2aXtmqh",
        "outputId": "3805403b-0ded-4157-925c-c44b6e6d6320"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "102/102 [==============================] - 2s 3ms/step - loss: 0.6480 - accuracy: 0.6399\n",
            "Epoch 2/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.6185 - accuracy: 0.6693\n",
            "Epoch 3/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.5987 - accuracy: 0.6868\n",
            "Epoch 4/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.5866 - accuracy: 0.6887\n",
            "Epoch 5/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.5794 - accuracy: 0.7025\n",
            "Epoch 6/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.5736 - accuracy: 0.7015\n",
            "Epoch 7/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.5656 - accuracy: 0.7132\n",
            "Epoch 8/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.5662 - accuracy: 0.7064\n",
            "Epoch 9/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.5571 - accuracy: 0.7172\n",
            "Epoch 10/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.5506 - accuracy: 0.7209\n",
            "Epoch 11/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.5399 - accuracy: 0.7255\n",
            "Epoch 12/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.5319 - accuracy: 0.7402\n",
            "Epoch 13/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.5214 - accuracy: 0.7383\n",
            "Epoch 14/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.5178 - accuracy: 0.7442\n",
            "Epoch 15/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.7531\n",
            "Epoch 16/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.5036 - accuracy: 0.7500\n",
            "Epoch 17/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.4992 - accuracy: 0.7598\n",
            "Epoch 18/100\n",
            "102/102 [==============================] - 0s 5ms/step - loss: 0.4925 - accuracy: 0.7598\n",
            "Epoch 19/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4895 - accuracy: 0.7580\n",
            "Epoch 20/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.4864 - accuracy: 0.7656\n",
            "Epoch 21/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4812 - accuracy: 0.7666\n",
            "Epoch 22/100\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 0.4795 - accuracy: 0.7656\n",
            "Epoch 23/100\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 0.4778 - accuracy: 0.7672\n",
            "Epoch 24/100\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 0.4745 - accuracy: 0.7681\n",
            "Epoch 25/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.4706 - accuracy: 0.7745\n",
            "Epoch 26/100\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 0.4689 - accuracy: 0.7718\n",
            "Epoch 27/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7727\n",
            "Epoch 28/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7822\n",
            "Epoch 29/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.4639 - accuracy: 0.7785\n",
            "Epoch 30/100\n",
            "102/102 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7755\n",
            "Epoch 31/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7764\n",
            "Epoch 32/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7770\n",
            "Epoch 33/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7779\n",
            "Epoch 34/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7767\n",
            "Epoch 35/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7779\n",
            "Epoch 36/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7856\n",
            "Epoch 37/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7874\n",
            "Epoch 38/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7831\n",
            "Epoch 39/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7791\n",
            "Epoch 40/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7844\n",
            "Epoch 41/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7837\n",
            "Epoch 42/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7859\n",
            "Epoch 43/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7828\n",
            "Epoch 44/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7865\n",
            "Epoch 45/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7847\n",
            "Epoch 46/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7862\n",
            "Epoch 47/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7871\n",
            "Epoch 48/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7880\n",
            "Epoch 49/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7902\n",
            "Epoch 50/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7880\n",
            "Epoch 51/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.7936\n",
            "Epoch 52/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.7874\n",
            "Epoch 53/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7883\n",
            "Epoch 54/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7908\n",
            "Epoch 55/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7877\n",
            "Epoch 56/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7850\n",
            "Epoch 57/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7859\n",
            "Epoch 58/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7914\n",
            "Epoch 59/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.7920\n",
            "Epoch 60/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7893\n",
            "Epoch 61/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7933\n",
            "Epoch 62/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7877\n",
            "Epoch 63/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7856\n",
            "Epoch 64/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7908\n",
            "Epoch 65/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7890\n",
            "Epoch 66/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7905\n",
            "Epoch 67/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7890\n",
            "Epoch 68/100\n",
            "102/102 [==============================] - 0s 5ms/step - loss: 0.4374 - accuracy: 0.7920\n",
            "Epoch 69/100\n",
            "102/102 [==============================] - 0s 5ms/step - loss: 0.4392 - accuracy: 0.7896\n",
            "Epoch 70/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7914\n",
            "Epoch 71/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7896\n",
            "Epoch 72/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7874\n",
            "Epoch 73/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7911\n",
            "Epoch 74/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7948\n",
            "Epoch 75/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.7926\n",
            "Epoch 76/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7923\n",
            "Epoch 77/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7914\n",
            "Epoch 78/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7945\n",
            "Epoch 79/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7923\n",
            "Epoch 80/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7926\n",
            "Epoch 81/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7920\n",
            "Epoch 82/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7945\n",
            "Epoch 83/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7954\n",
            "Epoch 84/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7954\n",
            "Epoch 85/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7954\n",
            "Epoch 86/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7939\n",
            "Epoch 87/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7899\n",
            "Epoch 88/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7979\n",
            "Epoch 89/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7929\n",
            "Epoch 90/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7908\n",
            "Epoch 91/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7951\n",
            "Epoch 92/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7902\n",
            "Epoch 93/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7948\n",
            "Epoch 94/100\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 0.4343 - accuracy: 0.7926\n",
            "Epoch 95/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7914\n",
            "Epoch 96/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7911\n",
            "Epoch 97/100\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 0.4334 - accuracy: 0.7893\n",
            "Epoch 98/100\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 0.4317 - accuracy: 0.7914\n",
            "Epoch 99/100\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 0.4338 - accuracy: 0.7936\n",
            "Epoch 100/100\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 0.4338 - accuracy: 0.7969\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7615\n",
            "[0.47208401560783386, 0.7615000009536743]\n",
            "63/63 [==============================] - 0s 2ms/step\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.77      0.84      1593\n",
            "           1       0.45      0.74      0.56       407\n",
            "\n",
            "    accuracy                           0.76      2000\n",
            "   macro avg       0.68      0.76      0.70      2000\n",
            "weighted avg       0.83      0.76      0.78      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,y_train = get_majority(3260,4890)\n",
        "y_preds3 = ANN(x_train,y_train,X_test,y_test,'binary_crossentropy',-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBIf_A4Bt8RL",
        "outputId": "73b297ca-53b5-470d-862b-8d3354f6daa1"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "102/102 [==============================] - 2s 7ms/step - loss: 0.6588 - accuracy: 0.6276\n",
            "Epoch 2/100\n",
            "102/102 [==============================] - 1s 9ms/step - loss: 0.6202 - accuracy: 0.6607\n",
            "Epoch 3/100\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 0.6042 - accuracy: 0.6739\n",
            "Epoch 4/100\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 0.5910 - accuracy: 0.6868\n",
            "Epoch 5/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.5809 - accuracy: 0.6926\n",
            "Epoch 6/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.5734 - accuracy: 0.6969\n",
            "Epoch 7/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.5669 - accuracy: 0.7046\n",
            "Epoch 8/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.7138\n",
            "Epoch 9/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.5522 - accuracy: 0.7160\n",
            "Epoch 10/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.5421 - accuracy: 0.7282\n",
            "Epoch 11/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.5337 - accuracy: 0.7344\n",
            "Epoch 12/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.5250 - accuracy: 0.7448\n",
            "Epoch 13/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.5171 - accuracy: 0.7482\n",
            "Epoch 14/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7528\n",
            "Epoch 15/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7592\n",
            "Epoch 16/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4963 - accuracy: 0.7641\n",
            "Epoch 17/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4897 - accuracy: 0.7681\n",
            "Epoch 18/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7656\n",
            "Epoch 19/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.7690\n",
            "Epoch 20/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7724\n",
            "Epoch 21/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7690\n",
            "Epoch 22/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7712\n",
            "Epoch 23/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7752\n",
            "Epoch 24/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7727\n",
            "Epoch 25/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7748\n",
            "Epoch 26/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7742\n",
            "Epoch 27/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7752\n",
            "Epoch 28/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7752\n",
            "Epoch 29/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7807\n",
            "Epoch 30/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7798\n",
            "Epoch 31/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7791\n",
            "Epoch 32/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7807\n",
            "Epoch 33/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7804\n",
            "Epoch 34/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7844\n",
            "Epoch 35/100\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 0.4579 - accuracy: 0.7822\n",
            "Epoch 36/100\n",
            "102/102 [==============================] - 1s 10ms/step - loss: 0.4575 - accuracy: 0.7804\n",
            "Epoch 37/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7791\n",
            "Epoch 38/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.7816\n",
            "Epoch 39/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.7844\n",
            "Epoch 40/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.7825\n",
            "Epoch 41/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.7810\n",
            "Epoch 42/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.7831\n",
            "Epoch 43/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7859\n",
            "Epoch 44/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7837\n",
            "Epoch 45/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.7856\n",
            "Epoch 46/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.7834\n",
            "Epoch 47/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7856\n",
            "Epoch 48/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7902\n",
            "Epoch 49/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4485 - accuracy: 0.7853\n",
            "Epoch 50/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7877\n",
            "Epoch 51/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7868\n",
            "Epoch 52/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7871\n",
            "Epoch 53/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7868\n",
            "Epoch 54/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7917\n",
            "Epoch 55/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7865\n",
            "Epoch 56/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7896\n",
            "Epoch 57/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7893\n",
            "Epoch 58/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7939\n",
            "Epoch 59/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.7874\n",
            "Epoch 60/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7926\n",
            "Epoch 61/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7926\n",
            "Epoch 62/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7923\n",
            "Epoch 63/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7902\n",
            "Epoch 64/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7923\n",
            "Epoch 65/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7945\n",
            "Epoch 66/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7887\n",
            "Epoch 67/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7920\n",
            "Epoch 68/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.7896\n",
            "Epoch 69/100\n",
            "102/102 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.7917\n",
            "Epoch 70/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.4410 - accuracy: 0.7929\n",
            "Epoch 71/100\n",
            "102/102 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.7979\n",
            "Epoch 72/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.7966\n",
            "Epoch 73/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7923\n",
            "Epoch 74/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7914\n",
            "Epoch 75/100\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 0.4393 - accuracy: 0.7926\n",
            "Epoch 76/100\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 0.4400 - accuracy: 0.7951\n",
            "Epoch 77/100\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 0.4389 - accuracy: 0.7957\n",
            "Epoch 78/100\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 0.4401 - accuracy: 0.7877\n",
            "Epoch 79/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.4391 - accuracy: 0.7914\n",
            "Epoch 80/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7997\n",
            "Epoch 81/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7887\n",
            "Epoch 82/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7975\n",
            "Epoch 83/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7951\n",
            "Epoch 84/100\n",
            "102/102 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7972\n",
            "Epoch 85/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7969\n",
            "Epoch 86/100\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 0.4373 - accuracy: 0.7988\n",
            "Epoch 87/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7957\n",
            "Epoch 88/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7988\n",
            "Epoch 89/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7979\n",
            "Epoch 90/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7939\n",
            "Epoch 91/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.8021\n",
            "Epoch 92/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7994\n",
            "Epoch 93/100\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 0.4372 - accuracy: 0.7985\n",
            "Epoch 94/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.4336 - accuracy: 0.7923\n",
            "Epoch 95/100\n",
            "102/102 [==============================] - 1s 7ms/step - loss: 0.4353 - accuracy: 0.7939\n",
            "Epoch 96/100\n",
            "102/102 [==============================] - 1s 5ms/step - loss: 0.4331 - accuracy: 0.8015\n",
            "Epoch 97/100\n",
            "102/102 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.7936\n",
            "Epoch 98/100\n",
            "102/102 [==============================] - 1s 6ms/step - loss: 0.4331 - accuracy: 0.8012\n",
            "Epoch 99/100\n",
            "102/102 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.8006\n",
            "Epoch 100/100\n",
            "102/102 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7982\n",
            "63/63 [==============================] - 1s 7ms/step - loss: 0.4951 - accuracy: 0.7445\n",
            "[0.4951317608356476, 0.7444999814033508]\n",
            "63/63 [==============================] - 0s 3ms/step\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.74      0.82      1593\n",
            "           1       0.43      0.75      0.54       407\n",
            "\n",
            "    accuracy                           0.74      2000\n",
            "   macro avg       0.67      0.75      0.68      2000\n",
            "weighted avg       0.82      0.74      0.77      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,y_train = get_majority(4890,6370)\n",
        "y_preds4 = ANN(x_train,y_train,X_test,y_test,'binary_crossentropy',-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkV6jT8DuG2A",
        "outputId": "c4c7c726-f75a-4c74-bdee-c37f423494a5"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "98/98 [==============================] - 2s 4ms/step - loss: 0.6683 - accuracy: 0.5990\n",
            "Epoch 2/100\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.6220 - accuracy: 0.6486\n",
            "Epoch 3/100\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.6038 - accuracy: 0.6707\n",
            "Epoch 4/100\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.5917 - accuracy: 0.6900\n",
            "Epoch 5/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.6984\n",
            "Epoch 6/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.7080\n",
            "Epoch 7/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.5628 - accuracy: 0.7096\n",
            "Epoch 8/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.5532 - accuracy: 0.7206\n",
            "Epoch 9/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7251\n",
            "Epoch 10/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.5396 - accuracy: 0.7293\n",
            "Epoch 11/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7444\n",
            "Epoch 12/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7457\n",
            "Epoch 13/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7502\n",
            "Epoch 14/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.7537\n",
            "Epoch 15/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.7563\n",
            "Epoch 16/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.7659\n",
            "Epoch 17/100\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.4912 - accuracy: 0.7640\n",
            "Epoch 18/100\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.7691\n",
            "Epoch 19/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4787 - accuracy: 0.7714\n",
            "Epoch 20/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.4741 - accuracy: 0.7695\n",
            "Epoch 21/100\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.4721 - accuracy: 0.7765\n",
            "Epoch 22/100\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7736\n",
            "Epoch 23/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7746\n",
            "Epoch 24/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7775\n",
            "Epoch 25/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7804\n",
            "Epoch 26/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7801\n",
            "Epoch 27/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7852\n",
            "Epoch 28/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7826\n",
            "Epoch 29/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7862\n",
            "Epoch 30/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7875\n",
            "Epoch 31/100\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.7794\n",
            "Epoch 32/100\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7868\n",
            "Epoch 33/100\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7852\n",
            "Epoch 34/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7814\n",
            "Epoch 35/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7884\n",
            "Epoch 36/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7836\n",
            "Epoch 37/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7910\n",
            "Epoch 38/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7855\n",
            "Epoch 39/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7916\n",
            "Epoch 40/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7904\n",
            "Epoch 41/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7916\n",
            "Epoch 42/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7865\n",
            "Epoch 43/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7891\n",
            "Epoch 44/100\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7936\n",
            "Epoch 45/100\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7929\n",
            "Epoch 46/100\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7897\n",
            "Epoch 47/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7923\n",
            "Epoch 48/100\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7955\n",
            "Epoch 49/100\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7916\n",
            "Epoch 50/100\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7929\n",
            "Epoch 51/100\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7990\n",
            "Epoch 52/100\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7929\n",
            "Epoch 53/100\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7968\n",
            "Epoch 54/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7939\n",
            "Epoch 55/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7984\n",
            "Epoch 56/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7981\n",
            "Epoch 57/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7965\n",
            "Epoch 58/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7997\n",
            "Epoch 59/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7981\n",
            "Epoch 60/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7971\n",
            "Epoch 61/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7990\n",
            "Epoch 62/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7965\n",
            "Epoch 63/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7961\n",
            "Epoch 64/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8035\n",
            "Epoch 65/100\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.7987\n",
            "Epoch 66/100\n",
            "98/98 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.8013\n",
            "Epoch 67/100\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.8045\n",
            "Epoch 68/100\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.7987\n",
            "Epoch 69/100\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.8071\n",
            "Epoch 70/100\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.8003\n",
            "Epoch 71/100\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7990\n",
            "Epoch 72/100\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.7994\n",
            "Epoch 73/100\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.8026\n",
            "Epoch 74/100\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.8019\n",
            "Epoch 75/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.4195 - accuracy: 0.7997\n",
            "Epoch 76/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.4181 - accuracy: 0.8048\n",
            "Epoch 77/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4173 - accuracy: 0.7994\n",
            "Epoch 78/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.4157 - accuracy: 0.8087\n",
            "Epoch 79/100\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8035\n",
            "Epoch 80/100\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.4157 - accuracy: 0.8023\n",
            "Epoch 81/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.4171 - accuracy: 0.8029\n",
            "Epoch 82/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4148 - accuracy: 0.8068\n",
            "Epoch 83/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.8074\n",
            "Epoch 84/100\n",
            "98/98 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.8071\n",
            "Epoch 85/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.4119 - accuracy: 0.8048\n",
            "Epoch 86/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4116 - accuracy: 0.8068\n",
            "Epoch 87/100\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.4123 - accuracy: 0.8103\n",
            "Epoch 88/100\n",
            "98/98 [==============================] - 1s 5ms/step - loss: 0.4138 - accuracy: 0.8051\n",
            "Epoch 89/100\n",
            "98/98 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8013\n",
            "Epoch 90/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.4108 - accuracy: 0.8035\n",
            "Epoch 91/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4101 - accuracy: 0.8087\n",
            "Epoch 92/100\n",
            "98/98 [==============================] - 1s 10ms/step - loss: 0.4100 - accuracy: 0.8103\n",
            "Epoch 93/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4092 - accuracy: 0.8055\n",
            "Epoch 94/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4110 - accuracy: 0.8035\n",
            "Epoch 95/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.4101 - accuracy: 0.8103\n",
            "Epoch 96/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4082 - accuracy: 0.8071\n",
            "Epoch 97/100\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.4107 - accuracy: 0.8077\n",
            "Epoch 98/100\n",
            "98/98 [==============================] - 1s 7ms/step - loss: 0.4085 - accuracy: 0.8132\n",
            "Epoch 99/100\n",
            "98/98 [==============================] - 1s 6ms/step - loss: 0.4081 - accuracy: 0.8071\n",
            "Epoch 100/100\n",
            "98/98 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.8096\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7610\n",
            "[0.5083771347999573, 0.7609999775886536]\n",
            "63/63 [==============================] - 0s 4ms/step\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.76      0.84      1593\n",
            "           1       0.45      0.76      0.57       407\n",
            "\n",
            "    accuracy                           0.76      2000\n",
            "   macro avg       0.69      0.76      0.70      2000\n",
            "weighted avg       0.83      0.76      0.78      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_ped_final = y_preds1.copy()\n",
        "for i in range(len(y_preds1)):\n",
        "  total = y_preds1[i]+y_preds2[i]+y_preds3[i]+y_preds4[i]\n",
        "\n",
        "  if total > 1 :\n",
        "    y_ped_final[i] = 1\n",
        "  else:\n",
        "    y_ped_final[i] =0"
      ],
      "metadata": {
        "id": "jBtELrpquRnM"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test,y_ped_final))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSHWSu-8uYxC",
        "outputId": "09166d81-a3e8-423e-aa51-a02abd459be2"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.74      0.82      1593\n",
            "           1       0.43      0.78      0.55       407\n",
            "\n",
            "    accuracy                           0.75      2000\n",
            "   macro avg       0.68      0.76      0.69      2000\n",
            "weighted avg       0.83      0.75      0.77      2000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}